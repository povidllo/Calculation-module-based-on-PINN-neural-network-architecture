import numpy as np
import torch

def ac_generator(num_t, num_x, typ='train'):
    N_f = num_t*num_x
    t = np.linspace(0, 1, num_t).reshape(-1,1) # T x 1
    x = np.linspace(-1, 1, num_x).reshape(-1,1) # N x 1
    T = t.shape[0]
    N = x.shape[0]
    T_star = np.tile(t, (1, N)).T  # N x T
    X_star = np.tile(x, (1, T))  # N x T

    # Initial condition and boundary condition
    u = np.zeros((N, T))  # N x T
    u[:,0:1] = (x**2)*np.cos(np.pi*x)
    u[0,:] = -np.ones(T)
    u[-1,:] = u[0,:]

    t_data = T_star.flatten()[:, None]
    x_data = X_star.flatten()[:, None]
    u_data = u.flatten()[:, None]

    t_data_f = t_data.copy()
    x_data_f = x_data.copy()

    if typ == 'train':
        idx = np.random.choice(np.where((x_data == -1) | (x_data == 1))[0], num_t)
        t_data = t_data[idx]
        x_data = x_data[idx]
        u_data = u_data[idx]

        init_idx = np.random.choice(N-1, num_x-4, replace=False) + 1
        t_data = np.concatenate([t_data, np.ones((2,1)), np.zeros((num_x-4,1))], axis=0)
        x_data = np.concatenate([x_data, np.array([[-1], [1]]), x[init_idx]], axis=0)
        u_data = np.concatenate([u_data, -np.ones((2,1)), u[init_idx,0:1]], axis=0)

        return t_data, x_data, u_data, t_data_f, x_data_f

    else:
        return t_data_f, x_data_f

def data_generator():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    t_data, x_data, u_data, t_data_f, x_data_f = ac_generator(201, 513)
    variables = torch.FloatTensor(np.concatenate((t_data, x_data), axis=1)).to(device)
    variables_f = torch.FloatTensor(np.concatenate((t_data_f, x_data_f), axis=1)).to(device)
    variables_f.requires_grad = True
    u_data = torch.FloatTensor(u_data).to(device)
    # return {'train': variables_f, 'boundary': variables, 'boundary_true': u_data}
    return {'main': variables_f, 'secondary': variables, 'secondary_true': u_data}